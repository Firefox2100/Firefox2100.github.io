---
title: SVM学习笔记
date: 2020-2-22 10:40:21
categories:
- P.E.M.P.W.S.
tags:
- Object-tracking
- SVM
- SCK
---

> 在之前的文章里，我们已经进行了SIFT，CBWH和卡尔曼滤波的基础知识的学习。在这篇文章中，我们将进行SVM的简单梳理，因为SVM的有关内容应用非常广泛，且在我们要实现的算法中并不是主要部分，所以不深入探究。

## 什么是SVM

### 监督学习和无监督学习

在了解SVM之前，我们先来了解一下监督学习。机器学习分为两大类，分别是监督学习和无监督学习。在监督学习中，训练分类器的是**已知类型的样本**。例如，用一组已经人工归类完成的数据，比如潮汐水位值，已经人工标记为什么是正常数据，什么是异常数据来训练分类器，目的是通过将分类器的参数调整到适合现在的任务，即标记未来输入的潮汐水位数据。无监督学习则相反，送入分类器的数据是**未分类的数据**，即原始数据。这一部分的情况通常在无法人工标记，例如因为没有经验不知道怎么标记；或者是人工标记工作量太大，例如大型聚类算法的训练样本集可能含有上亿组数据，乃至更多。这个时候，分类器只负责挑出相似的样本，而忽略这些样本的实际意义，也没有与专业契合的经验公式。今天要讨论的SVM，属于监督学习。

### SVM的特点

SVM，即支持向量机(Support Vector Machine)，是一种二元分类器。二元分类器是指，它只负责将样本分成两类。它采用的分类方法是超平面分类，即，在多维空间中求解一个超平面，这个超平面将样本集分成两类。而因为它是监督学习，可以简单地理解为，将已经分类的样本集输入，获得一个模型，用这个模型对之后的未分类样本集进行分类。

## 线性可分性，损失函数，松弛变量和核方法

刚才提到，SVM通过超平面将样本分成两类。但是不是所有的样本集都可以通过这样的平面分开，所以面对这样的问题，需要采取一定的修正。

### 什么是线性可分性

在数学上定义，若存在一个超平面将目标空间的样本集分成两类，且任意一个样本到超平面的距离大于等于1，这个样本集具有线性可分性。想象三维空间的一个例子：一个桌子，上面放有一个架子，架子上有东西，桌子下面也有东西。此时，因为架子的存在，桌子上方和下方的东西距离桌面都超过1m，此时样本线性可分。平面上方的样本被称为正类样本，下方的叫负类样本。

比较容易注意到的是，这个定义其实不只有一个超平面，而是有三个，间隔面和与它平行，相隔1m的两个平面。间隔面称为决策边界，另外两个平面称为间隔边界。可以想到，存在样本恰好落在间隔边界的情况，而这种情况并不少见。这类样本被称为**支持向量**。

### 损失函数

如果有样本不满足线性可分性怎么办？比如，正类样本中的某些点可能偏向，乃至混入于负类样本，导致无法找到满足条件的超平面。此时引入损失函数的概念，描述分类损失。

在统计和概率上，损失函数指的是量化一个决策可能带来的损失的函数。而在SVM上，损失函数用来量化一个分类标准对整体带来的负面影响。那么通过尽量降低损失，就能够把分类过程最优化。最常用的损失函数之一是铰链损失函数，它就是应用了凸优化的思维，来对分类过程进行优化。

### 松弛变量

解决线性不可分的第二个思路是引入松弛变量。松弛变量的含义是，允许超平面不再是一个真正的平面，而有一定的松弛属性，即允许变量稍微超出正常阈值。基于松弛变量的SVM被称为软平面分类，引入它的好处是可以处理离群点，但是缺点是对于本身的结构有一定的破坏。

### 核函数

在之前的学习中，我们接触过核函数。而在SVM中，和函数的作用是通过非线性变换，将本来不是线性可分的样本集转换成线性可分的映射。想象这样一种样本集，有一个抛物面可以将其分为两类，那么，它是线性不可分，因为抛物面不是超平面；但是如果通过映射，很容易就能够将其变为线性可分的样本集，而这一映射最容易想到的是与二次函数有关。同理的，对于不同的样本集使用不同的核函数，将有助于样本分类。

## 经验风险与结构风险

与其他分类器类似，SVM也存在经验风险和结构风险。其中经验风险由损失函数定义，它所表示的是分类器的分类准确程度，损失越大，经验风险越高，即，虽然这一解已经是此种SVM能够找到的最优解，但是它仍然不能很好描述这个模型分类。而结构风险由分类器参数矩阵的范数定义，描述的是分类器的复杂程度与它带来的风险。复杂程度越高，过拟合可能性越大。但是相应的，结构越简单，经验风险就越大。除了硬边界的线性可分SVM，其他的SVM的整体风险均是这两个风险的线性组合。

## SVM如何操作

因为SVM相对较为基础，实现的方法也很多，还有像LIBSVM这样的软件包的存在，这里不再赘述。可以通过[这篇博客](https://www.cnblogs.com/jiangxinyang/p/9217424.html)来了解基础知识，而因为[LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)本身是开源的，使用起来也相当方便，还可以直接查看源码，在这里就不再继续说明了。至于SVM的选用，根据不同追踪情况一般不同，本算法中使用了C-SVC，但完全可能有其他改进方案。

这篇文章只是简单介绍了SVM的一些基础知识，在下一篇文章中，我们将真正进入完整的一个基于混合模型的目标追踪算法的探讨。
