---
title: CBWH学习笔记(二)
date: 2020-2-18 7:42:16
categories:
- P.E.M.P.W.S.
tags:
- Object-tracking
- CBWH
- SCK
---

> 在之前的文章里，我们学习了CBWH方法的一些基础知识，在这篇文章里，我们将继续学习CBWH方法。
> Credit:
>
> 本文中所引用的研究来自：
>
> J. Ning, Robust mean-shift tracking with corrected background-weighted histogram, DOI: 10.1049/iet-cvi.2009.0075
>
> 王芳芳，陈华 《动态背景下的视频目标跟踪》，硕士学位论文
>
> Kernel-Based Object Tracking, DOI: 10.1109/TPAMI.2003.1195991
>
> 成伟，柴毅 《均值漂移算法在视频目标跟踪中的应用》，硕士学位论文

## 图像追踪中的均值漂移

### 追踪目标的模型表示

#### 概率模型计算方法

上一篇文章内我们讲过将颜色空间等分成m个bin，这一等分过程用函数\\(b:R^2\rightarrow{1...m}\\)表示，可以表示为

$$b\left(x_i^*\right)$$

那么，目标模型的每一个特征可以描述为：

$$q_u={C\sum_{i=1}^nK\left(\middle\|x_i^*\middle\|^2\right)\delta\left[b\left(x_i^*\right)-u\right]}$$

看起来比较复杂，我们一个一个分析：

K是核函数的轮廓函数，由于跟踪过程中的目标遮挡或是背景的影响，目标模型中心附近的像素要比外面像素更可靠些。所以\\(k(x)\\)给目标中心的像素赋一个较大的权值，给边缘的赋一个较小的权值。

上式的\\(\delta\))是Kronecker delta函数。具体是什么将在下面解释。

C是一个标准化的常量系数，目的是归一化概率模型，让概率之和等于1。所以，C有：

$$C={1\over{\sum_{i=1}^nk\left(\middle\|x_i^*\middle\|^2\right)}}$$

可以看到，C其实是一个与x无关的常数，这一常数在运算的时候可以提前计算出来，降低运算量。

#### Kronecker delta函数

Kronecker函数其实是很简单的一个函数，本质是比较，两个参数是否相同。相同则函数值为1，不同则为0。函数为：

$$ \delta_{ij}=\lbrace_{1 \quad if\quad i=j}^{0 \quad if\quad i \ne j} $$

在本次学习中，可以看到，\\(\delta\))函数与定义有些不一样，本次的函数应该是：

$$ \delta(x)=\lbrace_{1 \quad if \quad x=0}^{0 \quad if \quad x \ne 0} $$

即，只有这个像素对应的特征是u的时候，才会被累加进入u的模型。

#### 核函数K

在均值漂移算法中，核函数最常用的是Epannechnikov函数，函数定义如下：

$$K_E(x)={\lbrace_{0\quad otherwise}^{c\left(1-\|x\|^2\right)\quad\|x\|\leq1}}$$

可以看到这是基于二次模型的加权核函数，比高斯加权核在运算上简单一些。

### 候选目标的模型表示

与追踪目标的模型类似，候选目标的特征\\(p_u(y)\\)可以表示为：

$$p_u(y)={C_h\sum_{i=1}^{n_h}k\left(\middle\|{ {y - x_i} \over h}\middle\|^2\right)\delta\left[b\left(x_i\right)-u\right]}$$

可以看到，与追踪目标的模型很像，但是有一些不一样的地方。

首先，公式中的常数项变成了\\(C_h\\)，因为公式改变，所以归一化常数也随之改变。新的归一化常数是：

$$C={1\over{\sum_{i=1}^{n_h}k\left(\middle\|{ { y - x_i }\over h}\middle\|^2\right)}}$$

这样才能保证概率模型的和仍为1。同时，核函数内也变成了比值关系。分子部分比较好理解，因为现在处理的是候选模型，区域中心已经发生改变，坐标系也要进行对应的变化。下面的h，在这次学习中是第一次遇到。h在这里表示带宽。

#### 带宽与带宽矩阵

在均值漂移中存在带宽矩阵的概念。它是一个\\(d \times d\\)的正定对称矩阵。而在均值漂移中，为了简化计算，往往使用单位矩阵加一个系数来作为带宽矩阵。所以带宽矩阵H：

$$H=h^2I$$

其中I是单位矩阵，而h就是带宽。带宽矩阵应该先行与核函数进行运算获得新的核函数，即：

$${K_H(y-x_i)}={|H|^{-1\over2}K(H^{-1\over2}(y-x_i))}$$

但是因为认为与单位矩阵成正比，所以退化至刚才的描述公式，省去了繁琐的计算。

### 相似性函数

之前说过，相似性函数是度量目标模型与目标候选模型之间的差异的函数。有研究表明，在均值漂移算法中，Bhattachyarya系数是优于目前其他选择的相似性函数。Bhattachyarya系数的定义是：

$$\rho(y)=\rho(p(y),q)=\sum_{u=1}^m\sqrt{p_u(y)q_u}$$

通过简单的不等式关系可以看出，它的值在0和1之间。两个模型越相似，它的值越接近1。完全一样时等于1。所以，在候选区域中迭代的时候，令相似性函数最大的位置即是目标位置。

### 漂移向量计算

为了让相似度最大，在当前帧进行追踪时，以前一帧的目标中心\\(y_0\\)为起始点，开始搜索最优目标。对相似性函数在\\(y_0\\)点泰勒展开，可以获得：

$$\rho[p(y),q] \approx \frac {1} {2} \sum_{u=1}^m \sqrt {p_u \left(y_0\right) q_u}+\frac {1}{2}\sum_{u=1}^m p_u(y)\sqrt{\frac{q_u}{p_u \left(y_0\right)}}$$

将候选模型描述函数代入上面的公式，可以获得：

$$\rho[p(y),q] \approx \frac {1} {2} \sum_{u=1}^m \sqrt {p_u \left(y_0\right) q_u}+\frac {C_h}{2} \sum_{u=1}^{nh} w_ik\left(\left\|\frac{y-x_i} {h}\right\|^2\right)$$

其中，为了简化表示我们引入了\\(w_i\\)，它的表达式是：

$$w_i=\sum_{u=1}^m \sqrt {\frac{q_u} {p_u \left(y_0 \right)}}\delta\left[b\left(x_i\right)-u\right]$$

可以看到，公式第一项是常数，所以只需令第二项最大即可。可以得到概率密度估计函数：

$$f_{n,k}=\frac {C_h} {2} \sum_{u=1}^{nh}w_ik\left(\left\|\frac{y-x_i}{h}\right\|^2\right)$$

那么可求得新的目标位置：

$$y_1=\frac{\sum_{i=1}^{n_h} x_i w_i g\left(\left\|\frac{y_0-x_i}{h}\right\|^2\right)}{\sum_{i=1}^{n_h}w_i g\left(\left\|\frac{y_0-x_i}{h} \right\|^{2}\right)}$$

所以本次漂移向量为：

$$m_{h,G}(y)=y_1-y_0=\frac{\sum_{i=1}^{n_h}x_i w_i g\left(\left\|\frac{y_0-x_i}{h}\right\|^2\right)}{\sum_{i=1}^{n_h}w_i g \left(\left\|\frac{y_0-x_i}{h}\right\|^2\right)}-y_0$$

至此，一次迭代就完成了。如果此时漂移向量小于阈值，则停止算法，认为已经找到目标准确位置；否则，继续迭代直到完成算法。

---

在本篇文章中，我们结束了对于均值漂移算法的基础部分的探讨。下一篇文章中，我们将从BWH开始，学习它的思路和方法，以及它的概念。之后将进入CBWH的学习。若有错误，还望指正。
