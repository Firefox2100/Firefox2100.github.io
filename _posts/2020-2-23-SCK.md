---
title: SCK学习笔记
date: 2020-2-23 7:45:16
categories:
- P.E.M.P.W.S.
tags:
- Object-tracking
- SCK
---

> 在之前的文章中，我们已经了解了SCK算法的基础知识。在这篇文章中，我们将通过完整构建算法的方式，来对SCK进行进一步的学习。
>
> Credit:
>
> 本文中所引用的研究来自：
>
> 王芳芳，陈华 《动态背景下的视频目标跟踪》，硕士学位论文

## SCK算法整体介绍

SCK算法，即SIFT and CBWH Kalman tracking，是王芳芳硕士在毕业论文中提出的一种目标追踪方法。这一算法使用复合模型描述目标，结合了它们的优点。

与在论文中提出的SCK算法不同的是，因为我将算法部署在了现实的实时环境下，同时也有运算能力的限制，所以对算法进行了一定的修改。鉴于原本的测试条件和开发环境中，视频内容是预先掌握了的，但是在现实环境中，无法对视频内容做出预判，也无法快速手动标记目标和提供训练集，所以原有的算法中一部分设计被省去，虽然降低了算法的性能，但是与实际的环境更适应。

## 算法流程

完整的流程图将在这一部分之后附上，因为存在一些变换技巧需要先行说明。这一部分的说明不按严格流程顺序而是按照逻辑顺序。

### SIFT正模型提取

因为CBWH本质上是均值漂移追踪算法，而SIFT本质上是匹配，所以SCK算法采用SIFT进行匹配，均值漂移作为辅助。

提取正模型1：正模型1是**由起始帧提取的目标SIFT特征**，它的范围是由人工指定的，在第一次启动算法的时候规定。

提取正模型2：正模型2是**由上一帧提取的目标SIFT特征**，是算法自行提取的，与当前帧最为接近，但是与第一帧可能有一定的变化。

### 匹配投票

在一对SIFT特征点匹配成功之后，可以计算这一对特征点的投票。计算公式是：

$$h(m)=r(m)-a(m)$$

其中，\\(r(m)\\)是特征点在当前帧的位置向量，\\(a(m)\\)是模型中对应特征点对于目标中心的位置向量。\\(h(m)\\)是对应特征点的投票，意义是通过这一个特征点获得的目标中心位置。

因为存在匹配错误和特征点的\\(a(m)\\)错误的可能，所以在进行整合之前需要排除离群点。计算全部匹配成功的特征点之间的距离，排除最小距离大于阈值的点。这一部分点属于游离点，因为离它最近的点都在阈值之外。

在排除离群点之后就是加权投票。每个特征点的权值与其\\(a(m)\\)的长度的指数成反比。就是说，以\\(e\\)为底，\\(a(m)\\)为指数，与其成反比。这样，权值在特征点远离模型目标中心的时候下降较快，因为靠近中心点的特征点更为可靠。公式：

$$weight_i \propto e^{-|a_i|}$$

将乘以权值的投票累加，获得最终位置。若使用的是第一帧的模型，即正模型1，那么将获得位置p1；使用正模型2则将获得位置p2。

### 卡尔曼滤波在SCK中的作用

在每次进行真正的图像追踪之前，SCK算法用卡尔曼滤波先根据之前构建的运动模型，以及上一帧的状态进行一次预测。这一预测标定了一个可能的目标位置，之后的SIFT特征点提取将在预测的目标中心附近完成，以降低运算量并且防止远处的背景干扰。在每次获得一帧中的目标的基于追踪的位置之后，将利用结果对卡尔曼模型进行修正。因为预测过程较为简单，所以在之后重点关注修正过程。

### CBWH跟踪

因为虽然CBWH的收敛性较好，但也容易陷入局部最优，同时为了降低计算量，CBWH追踪的起始点被设定为卡尔曼滤波的预测位置，从这个点出发，经过一定次数的迭代，CBWH将收敛至一个中心点，此时CBWH追踪框内的背景加权颜色直方图特征和模型一致。这一中心点标记为p3。

### 位置融合与卡尔曼修正

以p1，p2，p3为中心，获取三个可能中心的周边区域patch1，patch2，patch3。之后将它们与第一帧的初始化目标块patch进行比较，获取相似度。在计算相似度之前，先将图像块处理到规范化分辨率\\(15\times 15\\)。规范化的目的是方便之后统一处理，规范化使用标准的平均映射方法。相似度使用如下函数计算：

$$\text{Similarity}\left(\text{patch}_{i},\text{patch}\right)= 0.5 \left(\mathrm{NCC}\left(\text{patch}_{i},\text{patch}\right) +1\right),\quad i=1,2,3$$

其中，

$$NCC(\text{pa1,pa})=\frac{1}{n-1} \sum_{i=1}^n\frac{\left( pa1_i - \overline {pa1}_i \right) \left( pa2_i- \overline {pa2}_i \right) }{\sigma_1\sigma_2}$$

\\(\overline {pa1}\\)和\\(\overline {pa2}\\)分别是\\(pa1\\)和\\(pa1\\)的均值向量，\\(\sigma_1\\)和\\(\sigma_2\\)分别是它们的标准差。因为NCC的值在-1~1之间，所以通过归一化，将其转化为0~1的数。

以经过归一化的相似度作为权值，将加权得到的结果作为观测值送入卡尔曼滤波器，获得的结果就是修正之后的最优位置。

### 尺度及尺寸判定

因为CBWH比较依赖于目标追踪窗口的大小，过大的窗口会混入大量的背景特征，过小的窗口又导致无法完全获得整个目标的特征。所以，需要使用一定的方法判定目标当前的尺寸和特征尺度。

根据前一帧与当前帧的特征点匹配情况， 分别计算前一帧内特征点之间的欧氏距离， 以
及当前帧内特征点之间的欧氏距离， 利用相应点对的欧氏距离之比得到尺度变化。 令前一帧
特征点的位置为\\(\text{loc_p}^i, \quad i=1,....mp\\)，当前帧的匹配特征点位置为\\(\text{loc_c}^i, \quad i=1,....mp\\)，\\(dist\_p_{u,v}\\)和\\(dist\_c_{u,v}\\)是某两个特征点之间的欧氏距离，那么找到：

$$\mathbf{Sp}_{\mathrm u,\mathrm v}=\left\{ \frac{dist_-c_{u,v}}{dist_-p_{u,v}},\mathrm u \neq \mathrm v \right\}_{\mathrm u=1}$$

并进行排序，取中值作为目标相对于前一帧的尺度变化。同理，与第一帧的特征点进行运算，可以得到相对于第一帧的尺度变化。

### SVM分类

对于匹配失败的特征点，进行SVM分类，分类特征是目标点/背景点。因为现实使用中无法做到手动标记目标点，所以，训练集准备采用基于Sobel边缘检测的图像分割技术，自动完成。或者，在对精确度要求更高的条件下，由用户手动快速选择目标的具体范围。SVM分类器更新的时候将自动完成训练集生成，因为更新帧出现的并不频繁，所以可以采取SVM之外的运算更复杂但是精度更高的聚类方法进行训练集生成。

## 算法流程图

<img src="{{site.baseurl}}/assets/images/in_posts/2020_2_23/SCK.png">

---

到这里，SCK算法的基本内容就已经完成了（完结撒花）！之后我们将继续学习其他的图像追踪技术，同时，我也会继续在ZYNQ平台上部署这一追踪算法，并在有一定阶段性成果的时候不定期更新算法部署的进度，和学习成果。如果有兴趣，或者有任何意见或建议，欢迎一起讨论！
